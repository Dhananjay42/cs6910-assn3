{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOdzwZt1XbykPmWCYluOo0B",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dhananjay42/cs6910-assn3/blob/main/assn3_nb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##CS6910: Assignment-3\n",
        "-- Submitted by Dhananjay Balakrishnan, ME19B012"
      ],
      "metadata": {
        "id": "90nAoRsb0UqA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Setup and Loading the Dataset"
      ],
      "metadata": {
        "id": "ixsJcIep0eUZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-Levenshtein"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdw6pniAfp28",
        "outputId": "2436ccec-46c3-4f14-ad53-0237dd586f7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting python-Levenshtein\n",
            "  Downloading python_Levenshtein-0.21.0-py3-none-any.whl (9.4 kB)\n",
            "Collecting Levenshtein==0.21.0 (from python-Levenshtein)\n",
            "  Downloading Levenshtein-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (174 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.1/174.1 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rapidfuzz<4.0.0,>=2.3.0 (from Levenshtein==0.21.0->python-Levenshtein)\n",
            "  Downloading rapidfuzz-3.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m53.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, Levenshtein, python-Levenshtein\n",
            "Successfully installed Levenshtein-0.21.0 python-Levenshtein-0.21.0 rapidfuzz-3.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "import Levenshtein"
      ],
      "metadata": {
        "id": "AF-X9IyU3Kru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVnNtzrR0pUt",
        "outputId": "493b0a8b-51e3-45cc-e4c1-f06c60015bb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = '/content/gdrive/MyDrive/CS6910_A3/aksharantar_sampled/tam/'"
      ],
      "metadata": {
        "id": "QUrlh1ep0bLk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def obtain_data(dir):\n",
        "  x = []\n",
        "  y = []\n",
        "\n",
        "  with open(dir, 'r') as file:\n",
        "    reader = csv.DictReader(file, fieldnames=['x', 'y'])\n",
        "  \n",
        "    for row in reader:\n",
        "      x.append(row['x'])\n",
        "      y.append(row['y'])\n",
        "    \n",
        "  return x, y"
      ],
      "metadata": {
        "id": "i2Dr1QDU0qGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, y_train = obtain_data(data_dir + 'tam_train.csv')\n",
        "x_test, y_test = obtain_data(data_dir + 'tam_test.csv')\n",
        "x_val, y_val = obtain_data(data_dir + 'tam_valid.csv')"
      ],
      "metadata": {
        "id": "faHyeHRY3lVl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0, 2):\n",
        "  print(x_train[i], y_train[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ya5oC143xZ8",
        "outputId": "a3f72fcc-99c9-488d-f98d-9603b950a76d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "thottacharya தொட்டாச்சார்ய\n",
            "menmaithaan மென்மைதான்\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_token = 0\n",
        "end_token = 1"
      ],
      "metadata": {
        "id": "0s9Mght5EB7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eng_characters = {}"
      ],
      "metadata": {
        "id": "NkOaYBL_-qy2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Language:\n",
        "  def __init__(self, name):\n",
        "    self.name = name\n",
        "    self.char2index = {}\n",
        "    self.index2char = {0: \"SOS\", 1: \"EOS\", 2: \"unknown\"}\n",
        "    self.n_chars = 3  # Count SOS and EOS\n",
        "    self.max_size = 0\n",
        "\n",
        "  def update_vocab(self, x):\n",
        "    for word in x:\n",
        "      if len(word) > self.max_size:\n",
        "        self.max_size = len(word)\n",
        "\n",
        "      for letter in word:\n",
        "        if letter not in self.char2index.keys():\n",
        "          self.char2index[letter] = self.n_chars\n",
        "          self.index2char[self.n_chars] = letter\n",
        "          self.n_chars = self.n_chars + 1\n",
        "  \n",
        "  def get_index(self, character):\n",
        "    if character in self.char2index.keys():\n",
        "      return self.char2index[character]\n",
        "    else:\n",
        "      return 2\n",
        "  \n",
        "  def get_character(self, index):\n",
        "    if index == 2:\n",
        "      return '$'\n",
        "    else:\n",
        "      return self.index2char[index]"
      ],
      "metadata": {
        "id": "KItsHUzs9zPP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "english = Language('eng')\n",
        "tamil = Language('tam')"
      ],
      "metadata": {
        "id": "Dt5eia4S_tLQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "english.update_vocab(x_train)\n",
        "tamil.update_vocab(y_train)"
      ],
      "metadata": {
        "id": "OQBYGHJl_2fQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encoded_word(language, word):\n",
        "  coded = [language.get_index(letter) for letter in word]\n",
        "  coded.append(end_token)\n",
        "  return coded\n",
        "\n",
        "def get_pairs(lang1, lang2, inputs, targets):\n",
        "  return [(torch.tensor(encoded_word(lang1, x), dtype=torch.long, device=device).view(-1, 1), torch.tensor(encoded_word(lang2, y), dtype=torch.long, device=device).view(-1, 1)) \n",
        "  for (x,y) in zip(inputs,targets)]\n",
        "\n",
        "def decoded_word(language, encoded_word):\n",
        "  characters = [language.get_character(num) for num in encoded_word[:-1]]\n",
        "  decoded = ''.join(characters)\n",
        "  return decoded"
      ],
      "metadata": {
        "id": "yCsWlmkwAlwC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = get_pairs(english, tamil, x_train, y_train)\n",
        "test_data = get_pairs(english, tamil, x_test, y_test)\n",
        "val_data = get_pairs(english, tamil, x_val, y_val)"
      ],
      "metadata": {
        "id": "4VDupcI8m3aS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#RNN without Attention"
      ],
      "metadata": {
        "id": "63vUwSCMWDMn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self, inp_vocab_size, embedding_size, n_layers, hl_size, dropout, cell_type, bidirectional):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.vocab_size = inp_vocab_size\n",
        "    self.embedding_size = embedding_size\n",
        "    self.n_layers = n_layers\n",
        "    self.hl_size = hl_size\n",
        "    self.bidirectional = bidirectional\n",
        "    self.cell_type = cell_type\n",
        "    self.dropout = dropout\n",
        "\n",
        "    if cell_type == 'RNN':\n",
        "      self.cell = nn.RNN(self.embedding_size, self.hl_size, num_layers = self.n_layers, dropout = self.dropout, bidirectional = self.bidirectional).to(device)\n",
        "    elif cell_type == 'GRU':\n",
        "      self.cell = nn.GRU(self.embedding_size, self.hl_size, num_layers = self.n_layers, dropout = self.dropout, bidirectional = self.bidirectional).to(device)\n",
        "    elif cell_type == 'LSTM':\n",
        "      self.cell = nn.LSTM(self.embedding_size, self.hl_size, num_layers = self.n_layers, dropout = self.dropout, bidirectional = self.bidirectional).to(device)\n",
        "    else:\n",
        "      print('Wrong Cell Type.')\n",
        "      exit()\n",
        "    self.embedding_layer = nn.Embedding(self.vocab_size, self.embedding_size).to(device)\n",
        "  \n",
        "  def forward(self, input, hidden, c = 0):\n",
        "    embedded = self.embedding_layer(input).view(1, 1, -1)\n",
        "    if self.cell_type != 'LSTM':\n",
        "      output, hidden = self.cell(embedded, hidden)\n",
        "      \n",
        "      return output, hidden\n",
        "\n",
        "    else:\n",
        "      output, (hidden, c) = self.cell(embedded, (hidden, c))\n",
        "\n",
        "      return output, hidden, c\n",
        "  \n",
        "  def init_hidden(self):\n",
        "    if self.bidirectional:\n",
        "      return torch.zeros(self.n_layers*2, 1, self.hl_size, device = device)\n",
        "    else:\n",
        "      return torch.zeros(self.n_layers, 1, self.hl_size, device = device)"
      ],
      "metadata": {
        "id": "0zU4N_wh70Wc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderVanilla(nn.Module):\n",
        "  def __init__(self, out_vocab_size, embedding_size, n_layers, hl_size, dropout, cell_type, bidirectional):\n",
        "    super(DecoderVanilla, self).__init__()\n",
        "    self.vocab_size = out_vocab_size\n",
        "    self.embedding_size = embedding_size\n",
        "    self.n_layers = n_layers\n",
        "    self.hl_size = hl_size\n",
        "    self.softmax = nn.LogSoftmax(dim=1)\n",
        "    self.cell_type = cell_type\n",
        "    self.bidirectional = bidirectional\n",
        "    self.dropout = dropout\n",
        "\n",
        "    if self.bidirectional:\n",
        "      self.linear = nn.Linear(2*self.hl_size, self.vocab_size).to(device)\n",
        "    else:\n",
        "      self.linear = nn.Linear(self.hl_size, self.vocab_size).to(device)\n",
        "\n",
        "    if cell_type == 'RNN':\n",
        "      self.cell = nn.RNN(self.embedding_size, self.hl_size, num_layers = self.n_layers, dropout = self.dropout, bidirectional = self.bidirectional).to(device)\n",
        "    elif cell_type == 'GRU':\n",
        "      self.cell = nn.GRU(self.embedding_size, self.hl_size, num_layers = self.n_layers, dropout = self.dropout, bidirectional = self.bidirectional).to(device)\n",
        "    elif cell_type == 'LSTM':\n",
        "      self.cell = nn.LSTM(self.embedding_size, self.hl_size, num_layers = self.n_layers, dropout = self.dropout, bidirectional = self.bidirectional).to(device)\n",
        "    else:\n",
        "      print('Wrong Cell Type.')\n",
        "      exit()\n",
        "    \n",
        "    self.embedding_layer = nn.Embedding(self.vocab_size, self.embedding_size).to(device)\n",
        "  \n",
        "  def forward(self, input, hidden, c = 0):\n",
        "    embedded = self.embedding_layer(input).view(1, 1, -1)\n",
        "    output = F.relu(embedded)\n",
        "\n",
        "    if self.cell_type != 'LSTM':\n",
        "      output, hidden = self.cell(output, hidden)\n",
        "      output = self.linear(output[0])\n",
        "      output = self.softmax(output)\n",
        "      return output, hidden\n",
        "    else:\n",
        "      output, (hidden, c) = self.cell(output, (hidden, c))\n",
        "      output = self.linear(output[0])\n",
        "      output = self.softmax(output)\n",
        "      return output, hidden, c"
      ],
      "metadata": {
        "id": "FU3vbDoy1cm8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class seq2seq_vanilla():\n",
        "  def __init__(self, inp_language, out_language, embedding_size, n_layers, hl_size, dropout = 0.2, cell_type = 'LSTM', lr = 0.01, teacher_forcing_ratio = 0.5,bidirectional_flag = False):\n",
        "    self.encoder = Encoder(inp_language.n_chars, embedding_size, n_layers, hl_size, dropout, cell_type, bidirectional = bidirectional_flag)\n",
        "    self.decoder = DecoderVanilla(out_language.n_chars, embedding_size, n_layers, hl_size, dropout, cell_type, bidirectional = bidirectional_flag)\n",
        "    self.lr = lr\n",
        "    self.teacher_forcing = teacher_forcing_ratio\n",
        "    self.max_length = out_language.max_size\n",
        "    self.cell_type = cell_type\n",
        "\n",
        "    self.encoder_optimizer = optim.SGD(self.encoder.parameters(), lr=self.lr)\n",
        "    self.decoder_optimizer = optim.SGD(self.decoder.parameters(), lr = self.lr)\n",
        "\n",
        "    self.loss_fn = nn.NLLLoss()\n",
        "\n",
        "  def train_step(self, input, target):\n",
        "    encoder_hidden = self.encoder.init_hidden()\n",
        "    encoder_c = self.encoder.init_hidden()\n",
        "\n",
        "    self.encoder_optimizer.zero_grad()\n",
        "    self.decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input.size(0)\n",
        "    target_length = target.size(0)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    for i in range(0, input_length):\n",
        "      if self.cell_type != 'LSTM':\n",
        "        encoder_output, encoder_hidden = self.encoder.forward(input[i], encoder_hidden)\n",
        "      else:\n",
        "        encoder_output, encoder_hidden, encoder_c = self.encoder.forward(input[i], encoder_hidden, encoder_c)\n",
        "    \n",
        "    decoder_input = torch.tensor([[start_token]], device=device)\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "    decoder_c = encoder_c\n",
        "\n",
        "    num = random.random()\n",
        "\n",
        "    if num < self.teacher_forcing:\n",
        "      #here, we use teacher forcing. \n",
        "      for j in range(0, target_length):\n",
        "        if self.cell_type != 'LSTM':\n",
        "          decoder_output, decoder_hidden = self.decoder.forward(decoder_input, decoder_hidden)\n",
        "        else:\n",
        "          decoder_output, decoder_hidden, decoder_c = self.decoder.forward(decoder_input, decoder_hidden, decoder_c)\n",
        "\n",
        "        loss = loss + self.loss_fn(decoder_output, target[j])\n",
        "        decoder_input = target[j]#.unsqueeze(0)\n",
        "\n",
        "    else:\n",
        "      #here, there is no teacher forcing. the predictions themselves are used. \n",
        "      for j in range(0, target_length):\n",
        "        if self.cell_type != 'LSTM':\n",
        "          decoder_output, decoder_hidden = self.decoder.forward(decoder_input, decoder_hidden)\n",
        "        else:\n",
        "          decoder_output, decoder_hidden, decoder_c = self.decoder.forward(decoder_input, decoder_hidden, decoder_c)\n",
        "\n",
        "        loss = loss + self.loss_fn(decoder_output, target[j])\n",
        "        value, index = decoder_output.topk(1)\n",
        "        decoder_input = index.squeeze().detach()\n",
        "        if decoder_input.item() == end_token:\n",
        "          break\n",
        "      \n",
        "            \n",
        "    loss.backward()\n",
        "    self.encoder_optimizer.step()\n",
        "    self.decoder_optimizer.step()\n",
        "\n",
        "    return loss.item()/target_length\n",
        "  \n",
        "  def predict(self, input, target):\n",
        "    with torch.no_grad():\n",
        "      encoder_hidden = self.encoder.init_hidden()\n",
        "      encoder_c = self.encoder.init_hidden()\n",
        "\n",
        "      input_length = input.size(0)\n",
        "      for i in range(0, input_length):\n",
        "        if self.cell_type != 'LSTM':\n",
        "          encoder_output, encoder_hidden = self.encoder.forward(input[i], encoder_hidden)\n",
        "        else:\n",
        "          encoder_output, encoder_hidden, encoder_c = self.encoder.forward(input[i], encoder_hidden, encoder_c)\n",
        "\n",
        "      decoder_input = torch.tensor([[start_token]], device=device)\n",
        "      decoder_hidden = encoder_hidden\n",
        "      decoder_c = encoder_c\n",
        "\n",
        "      outputs = []\n",
        "      for i in range(0, self.max_length):\n",
        "        if self.cell_type != 'LSTM':\n",
        "          decoder_output, decoder_hidden = self.decoder.forward(decoder_input, decoder_hidden)\n",
        "        else:\n",
        "          decoder_output, decoder_hidden, decoder_c = self.decoder.forward(decoder_input, decoder_hidden, decoder_c)\n",
        "\n",
        "        value, index = decoder_output.data.topk(1)\n",
        "        decoder_input = index.squeeze().detach()\n",
        "        outputs.append(decoder_input.item())\n",
        "        if decoder_input.item() == end_token:\n",
        "          break\n",
        "\n",
        "      return outputs\n",
        "\n",
        "\n",
        "  def evaluate(self, data):\n",
        "    correct = 0\n",
        "    character_wise = 0\n",
        "    count = 0\n",
        "    total_distance = 0\n",
        "\n",
        "    for pair in data:\n",
        "      input = pair[0]\n",
        "      target = pair[1]\n",
        "      pred = self.predict(input, target)\n",
        "      target = target.tolist()\n",
        "      target = [t[0] for t in target]\n",
        "\n",
        "      #if count%500 == 0:\n",
        "        #print(decoded_word(tamil,pred), decoded_word(tamil,target))\n",
        "      #count = count + 1\n",
        "\n",
        "      pred_word = decoded_word(tamil,pred)\n",
        "      tar_word = decoded_word(tamil,target)\n",
        "      \n",
        "      if pred_word == tar_word:\n",
        "        correct = correct + 1\n",
        "      \n",
        "      total_distance = total_distance + min((Levenshtein.distance(pred_word, tar_word)/max(len(tar_word),len(pred_word))), 1)\n",
        "    \n",
        "    avg_distance = total_distance/len(data)\n",
        "    char_acc = 1 - avg_distance\n",
        "    acc = correct/len(data)\n",
        "\n",
        "\n",
        "    return acc, char_acc"
      ],
      "metadata": {
        "id": "XtBOmSCGcuka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = seq2seq_vanilla(inp_language = english, out_language = tamil, embedding_size = 64, n_layers = 2, hl_size = 128)"
      ],
      "metadata": {
        "id": "-UWaDWHPnXPN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_iters = 75000"
      ],
      "metadata": {
        "id": "uKHso_WvDWjg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(val_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asm1dpLKgJTi",
        "outputId": "568eac4f-7d36-4e62-9128-f0f1a9afaafc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4096\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_pairs = [random.choice(train_data) for i in range(0, n_iters)]"
      ],
      "metadata": {
        "id": "-_nDKVgTNmnE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss = 0\n",
        "for i in range(0, n_iters):\n",
        "  training_pair = training_pairs[i]\n",
        "  x = training_pair[0]\n",
        "  y = training_pair[1]\n",
        "  loss = model.train_step(x, y)\n",
        "  train_loss = train_loss + loss\n",
        "\n",
        "  if (i+1)%5000 == 0:\n",
        "    print('------------------------------------------------')\n",
        "    print('train loss is:', train_loss/5000)\n",
        "    test_acc, char_acc = model.evaluate(val_data)\n",
        "    print(f'test accuracy is {test_acc} and character-wise accuracy is {char_acc}')\n",
        "    train_loss = 0"
      ],
      "metadata": {
        "id": "8yiauv0nN19Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Setting up wandb and hyperparameter sweep\n"
      ],
      "metadata": {
        "id": "voDdPUQRcmr9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb"
      ],
      "metadata": {
        "id": "nslhYuf3cr-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb"
      ],
      "metadata": {
        "id": "Uqzur-eWq6gY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wandb login"
      ],
      "metadata": {
        "id": "7AEcrBGrq6C8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "entity_name = \"dhananjayb\"\n",
        "project_name = \"cs6910-assignment-3\""
      ],
      "metadata": {
        "id": "8U4exWKvrA6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_iters = 75000"
      ],
      "metadata": {
        "id": "6YMELBegw5Qu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_pairs = [random.choice(train_data) for i in range(0, n_iters)]"
      ],
      "metadata": {
        "id": "2INJlUhew5Qv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sweep():\n",
        "  defaults = {\n",
        "      'epochs': 5,\n",
        "      'number_hidden_layers': 3,\n",
        "      'hidden_layer_size': 32,\n",
        "      'lamda': 0,\n",
        "      'learning_rate': 0.001,\n",
        "      'initialization_type': 'Xavier',\n",
        "      'optimizer': 'sgd',\n",
        "      'batch_size': 16,\n",
        "      'activation_fn': 'sigmoid'\n",
        "  }\n",
        "  wandb.init(config = defaults)\n",
        "  config = wandb.config\n",
        "\n",
        "  vanilla_model = seq2seq_vanilla(english, tamil, embedding_size = config.embedding_size, n_layers = config.n_layers, hl_size = config.hl_size, dropout = config.dropout, \\\n",
        "                          cell_type = config.cell_type, lr = 0.01, teacher_forcing_ratio = 0.5, bidirectional_flag = config.bidir)\n",
        "  \n",
        "  train_loss = 0\n",
        "  for i in range(0, n_iters):\n",
        "    training_pair = training_pairs[i]\n",
        "    x = training_pair[0]\n",
        "    y = training_pair[1]\n",
        "    loss = vanilla_model.train_step(x, y)\n",
        "    train_loss = train_loss + loss\n",
        "\n",
        "    if (i+1)%5000 == 0:\n",
        "      test_acc, char_acc = vanilla_model.evaluate(val_data)\n",
        "      train_loss = train_loss/5000\n",
        "      log_dict = {\"train_loss\":train_loss, \"test_accuracy\":test_acc, \"test_similarity\":char_acc}\n",
        "      wandb.log(log_dict)\n",
        "      train_loss = 0\n",
        "  \n",
        "  sweep_name = str(config.cell_type) + \"_emb\" + str(config.embedding_size) + \"_hl\" + str(config.hl_size) + \"_nl\" + str(config.n_layers) + \"_d\" + \\\n",
        "  str(config.dropout) + \"_bidir\" + str(config.bidir)\n",
        "  wandb.run.name = sweep_name\n",
        "\n",
        "  wandb.run.save()\n",
        "  wandb.run.finish()\n"
      ],
      "metadata": {
        "id": "6RvJeUKyrURQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hyperparameters = {\n",
        "      \"embedding_size\": {\n",
        "          'values': [32, 64, 128]\n",
        "      },\n",
        "      \"n_layers\": {\n",
        "          'values' : [1, 2, 3]\n",
        "      },\n",
        "      \"hl_size\": {\n",
        "          'values' : [32, 64, 128]\n",
        "      },\n",
        "      \"lamda\": {\n",
        "          'values': [0, 0.0005, 0.5]\n",
        "      },\n",
        "      \"dropout\":{\n",
        "        'values': [0, 0.2, 0.3]\n",
        "      },\n",
        "      \"cell_type\": {\n",
        "          'values' : ['RNN', 'GRU', 'LSTM']\n",
        "      }\n",
        "  }"
      ],
      "metadata": {
        "id": "dtIQrWBarYGl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sweep_configuration = {\n",
        "    'method': 'bayes',\n",
        "    'name': 'sweep',\n",
        "    'metric': {\n",
        "        'goal': 'maximize', \n",
        "        'name': 'test_similarity'\n",
        "        },\n",
        "    'parameters': hyperparameters\n",
        "}"
      ],
      "metadata": {
        "id": "ewDLFM5wsuy_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sweep_id = wandb.sweep(sweep_configuration, entity=entity_name, project=project_name)"
      ],
      "metadata": {
        "id": "6JISeTaQsyH4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}